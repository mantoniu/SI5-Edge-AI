# coco_person.yaml
path: ../datasets/coco_person
train: images/train
val: images/validation

names:
  0: person

download: |
  import kagglehub
  import json
  import os
  import shutil
  from pathlib import Path
  from tqdm import tqdm

  # 1. Téléchargement via KaggleHub
  print("Téléchargement du dataset depuis Kaggle...")
  root_path = Path(kagglehub.dataset_download("asrulsaid/coco-person"))
  
  # Chemins source basés sur ta config
  src_images = root_path / "fiftyone/coco-2017/train/data"
  src_labels_json = root_path / "fiftyone/coco-2017/train/labels.json"

  
  # Chemins destination
  dest_root = Path(yaml['path'])
  
  def process_coco_segmentation(limit=500, split='train'):
      img_dest = dest_root / f"images/{split}"
      lb_dest = dest_root / f"labels/{split}"
      img_dest.mkdir(parents=True, exist_ok=True)
      lb_dest.mkdir(parents=True, exist_ok=True)

      with open(root_path / "fiftyone/coco-2017" / split / "labels.json", 'r') as f:
          data = json.load(f)

      # Créer un dictionnaire pour trouver les images par ID
      images_dict = {img['id']: img for img in data['images']}
      
      count = 0
      print(f"Filtrage et conversion pour {split} (limite: {limit})...")
      
      for ann in tqdm(data['annotations']):
          if count >= limit: break
          
          # On vérifie si c'est une personne (dans COCO l'ID est souvent 1) 
          # et si l'annotation contient de la segmentation (masques)
          if ann.get('segmentation') and len(ann['segmentation']) > 0:
              image_info = images_dict.get(ann['image_id'])
              if not image_info: continue
              
              img_name = image_info['file_name']
              src_img_path = root_path / "fiftyone/coco-2017" / split / "data" / img_name
              
              if src_img_path.exists():
                  # 1. Copier l'image
                  shutil.copy(src_img_path, img_dest / img_name)
                  
                  # 2. Créer le label YOLO (Polygones)
                  lb_path = lb_dest / Path(img_name).with_suffix('.txt')
                  with open(lb_path, 'a') as f_lb:
                      # Format YOLO Seg: <class_id> <x1> <y1> <x2> <y2> ...
                      # Les coordonnées COCO sont en pixels, YOLO en normalisé (0-1)
                      w, h = image_info['width'], image_info['height']
                      for seg in ann['segmentation']:
                          if isinstance(seg, list): # Format polygone standard
                              normalized_coords = []
                              for i in range(0, len(seg), 2):
                                  normalized_coords.append(f"{seg[i]/w:.6f} {seg[i+1]/h:.6f}")
                              f_lb.write(f"0 {' '.join(normalized_coords)}\n")
                  count += 1

  # On génère 500 images pour le train et 100 pour la val
  process_coco_segmentation(limit=28377, split='train')
  process_coco_segmentation(limit=4687, split='validation')
  print("Dataset coco_person prêt !")